#### 1、RabbitMQ如何避免消息不被丢失

##### 生产者弄丢消息

原因：可能因为网络原因导致`RabbitMQ`未接收到消息数据，也可能`RabbitMQ`宕机消息丢失

解决方法：

> 1、生产者端使用事务。当一条消息发送之前，生产者端使用`channel.txSelect`开启事务，然后开始发送消息，如果`RabbitMQ`接收到消息，则使用`channel.txCommit`提交事务再发送下一条消息；如果消息队列未接收到消息，生产者端会收到异常报错，则使用`channel.txRollback`回滚事务，生产者开始重发消息。
>
> 2、使用confirm模式。生产者端开启`confirm`模式，会自动为消息分配唯一`id`标识，如果正常写入到`RabbitMQ`中，会回传一个`ack`消息，用以表示消息正常写入；若消息写入失败，则会回传`nack`消息，表示消息写入失败可以重试发送。
>
> 3、两种解决方式的不同：事务更耗费性能，因为每发送一条数据必须等到事务提交后才能发送下一条数据，这就造成数据的吞吐量下降影响性能；而`confirm`模式是异步进行的，生产者端无需等到`ack`消息，就可以执行发送下一条消息，所以更推荐使用`confirm`模式

##### RabbitMQ弄丢消息

原因：`RabbitMQ`宕机导致丢失消息

解决方法：开启持久化。步骤一、创建`queue`时，将其设置为持久化，目的是持久化`queue`元数据，但不会持久化`queue`里的数据；步骤二、发送消息时，将消息设置`deliveryMode=2`，目的是将消息持久化到硬盘中去。

如果消息还未持久化到硬盘中去，此时`RabbitMQ`宕机，如何解决丢失一部分数据？此时可以配合`confirm`模式将那一部分消息重新发送到恢复运行的消息队列中去

##### 消费者弄丢消息

原因：消费者会自动提交`ack`消息，当消息达到消费者端还未处理就宕机，就会造成消息丢失

解决方法：关闭自动提交`ack`。当消息达到消费者端，必须等到消息处理完毕时，才手动提交`ack`；如果消息队列迟迟未收到`ack`消息，就认为消息处理失败，将消息重新分配给别的消费者处理

#### 2、Kafka如何避免消息不被丢失

##### 消费者弄丢消息

原因：消费者自动提交`offset`，当消费者处理消息时就挂掉，就会导致消息丢失

解决方法：处理完毕手动提交`offset`（可能导致消息被重复消费，消费者端在处理完还尚未提交`offset`的情况下）

##### Kafka弄丢消息

原因：`leader`机器挂了，`follower`机器还未同步数据的情况下被推举成leader机器，造成部分数据丢失

解决方法：

> 1、给` topic`设置` replication.factor `参数：这个值必须大于 1，要求每个`partition `必须有至少 2 个副本。
>
> 2、在 `Kafka `服务端设置` min.insync.replicas `参数：这个值必须大于 1，这个是要求一个`leader `至少感知到有至少一个`follower`还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
>
> 3、在` producer`端设置 `acks=all`：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
>
> 4、在`producer`端设置 `retries=MAX`：这个是要求一旦写入失败，就无限重试。

